# Story 1.5: Error Handling Enhancement

<!-- Powered by BMAD‚Ñ¢ Core -->

## Status
üìù Draft - 2025-10-19

## Story

**As a** developer using Claude for AI-assisted development,
**I want** enhanced error handling with recovery strategies and structured error responses,
**so that** I receive actionable guidance when errors occur and the system can gracefully recover from transient failures.

## Acceptance Criteria

1. Enhanced error class hierarchy with recovery suggestions and error categories
2. Retry logic implemented for transient errors (network, filesystem locks)
3. Error context tracking (breadcrumbs) for debugging complex operations
4. Standardized error response format for MCP protocol with error codes
5. Error recovery strategies documented for each error type
6. Circuit breaker pattern for external operations (git, file system)
7. Error catalog documentation with all error types and handling strategies
8. Troubleshooting guide with common errors and solutions
9. Comprehensive unit tests (30+ tests) for error scenarios
10. Integration tests verify error recovery and retry logic

## Tasks / Subtasks

- [ ] **Task 1: Enhanced Error Class Hierarchy** (AC: 1, 4)
  - [ ] Review existing error hierarchy (ContextualizerError, ValidationError, FileOperationError, ConflictError)
  - [ ] Add `category` field to ContextualizerError (validation, filesystem, git, configuration, network, unknown)
  - [ ] Add `recoverySuggestions` array field to ContextualizerError
  - [ ] Add `isRetryable` boolean field to ContextualizerError
  - [ ] Add `retryCount` optional field to track retry attempts
  - [ ] Implement GitOperationError subclass for git-specific errors
  - [ ] Implement ConfigurationError subclass (update existing if present)
  - [ ] Implement NetworkError subclass for external service failures
  - [ ] Update error constructors to accept recovery suggestions
  - [ ] Unit test: All error classes have correct category
  - [ ] Unit test: Recovery suggestions properly stored
  - [ ] Unit test: isRetryable flag correctly set
  - [ ] Unit test: Error codes follow naming convention

- [ ] **Task 2: Error Context Tracking (Breadcrumbs)** (AC: 3)
  - [ ] Create `src/utils/error-context.ts`
  - [ ] Implement ErrorContext class with breadcrumb stack
  - [ ] Add `addBreadcrumb(operation: string, details?: unknown)` method
  - [ ] Add `getBreadcrumbs()` method returning breadcrumb array
  - [ ] Add `clear()` method to reset context
  - [ ] Integrate breadcrumbs into ContextualizerError details
  - [ ] Create AsyncLocalStorage-based context manager for tracking operation chains
  - [ ] Export `withErrorContext()` utility for wrapping operations
  - [ ] Unit test: Breadcrumbs added correctly
  - [ ] Unit test: Breadcrumbs included in error details
  - [ ] Unit test: Context cleared between operations
  - [ ] Unit test: Nested operations tracked properly
  - [ ] Unit test: AsyncLocalStorage isolation works

- [ ] **Task 3: Retry Logic Infrastructure** (AC: 2, 6)
  - [ ] Create `src/utils/retry.ts`
  - [ ] Implement `RetryConfig` interface (maxAttempts, delayMs, backoffMultiplier, maxDelayMs)
  - [ ] Implement `retryWithBackoff()` function with exponential backoff
  - [ ] Add predicate function to determine if error is retryable
  - [ ] Implement `CircuitBreaker` class for external operations
  - [ ] Circuit breaker states: CLOSED (normal), OPEN (failing), HALF_OPEN (testing)
  - [ ] Add circuit breaker configuration (failureThreshold, resetTimeoutMs, halfOpenMaxAttempts)
  - [ ] Integrate retry logic with error context tracking
  - [ ] Unit test: Retry attempts work with exponential backoff
  - [ ] Unit test: Max attempts respected
  - [ ] Unit test: Only retryable errors trigger retry
  - [ ] Unit test: Circuit breaker opens after threshold failures
  - [ ] Unit test: Circuit breaker half-open state works
  - [ ] Unit test: Circuit breaker closes after successful attempts
  - [ ] Unit test: Circuit breaker rejects requests when open

- [ ] **Task 4: Enhanced wrapToolHandler** (AC: 4, 5)
  - [ ] Update `wrapToolHandler` to include error codes in responses
  - [ ] Add recovery suggestions to error responses
  - [ ] Include breadcrumbs in error details when available
  - [ ] Add retry count to error responses when applicable
  - [ ] Format error responses for optimal readability in Claude
  - [ ] Create `formatErrorResponse()` utility function
  - [ ] Add structured error metadata (timestamp, category, isRetryable)
  - [ ] Unit test: Error codes included in responses
  - [ ] Unit test: Recovery suggestions formatted correctly
  - [ ] Unit test: Breadcrumbs included when present
  - [ ] Unit test: Retry information included when applicable
  - [ ] Unit test: Error response format matches MCP protocol

- [ ] **Task 5: Filesystem Operation Resilience** (AC: 2, 6)
  - [ ] Create `src/utils/fs-resilient.ts`
  - [ ] Implement `readFileWithRetry()` wrapper with retry logic
  - [ ] Implement `writeFileWithRetry()` wrapper with retry logic
  - [ ] Implement `ensureDirWithRetry()` wrapper with retry logic
  - [ ] Handle EBUSY, EACCES, EMFILE errors as retryable
  - [ ] Add file lock detection and waiting
  - [ ] Integrate with circuit breaker for file operations
  - [ ] Unit test: File read retries on EBUSY
  - [ ] Unit test: File write retries on lock contention
  - [ ] Unit test: Directory creation retries on transient errors
  - [ ] Unit test: Non-retryable errors fail immediately
  - [ ] Unit test: Circuit breaker protects filesystem

- [ ] **Task 6: Git Operation Resilience** (AC: 2, 6)
  - [ ] Create `src/utils/git-resilient.ts`
  - [ ] Implement `gitWithRetry()` wrapper for git commands
  - [ ] Handle git lock file contention (*.lock files)
  - [ ] Handle network errors for remote operations
  - [ ] Add retry logic for transient git failures
  - [ ] Integrate with circuit breaker for git operations
  - [ ] Add recovery suggestions for common git errors
  - [ ] Unit test: Git operations retry on lock contention
  - [ ] Unit test: Network errors trigger retry
  - [ ] Unit test: Non-retryable git errors fail immediately
  - [ ] Unit test: Circuit breaker protects git operations
  - [ ] Unit test: Recovery suggestions included

- [ ] **Task 7: Error Catalog Documentation** (AC: 7)
  - [ ] Create `docs/error-catalog.md`
  - [ ] Document all error types with examples
  - [ ] Document error codes and categories
  - [ ] Document recovery strategies for each error type
  - [ ] Include error message formats
  - [ ] Add code examples for each error type
  - [ ] Document when errors are retryable vs non-retryable
  - [ ] Document circuit breaker behavior
  - [ ] Add cross-references to troubleshooting guide

- [ ] **Task 8: Troubleshooting Guide** (AC: 8)
  - [ ] Create `docs/troubleshooting.md`
  - [ ] Document common error scenarios
  - [ ] Add step-by-step resolution guides
  - [ ] Include examples of error messages with solutions
  - [ ] Document debugging techniques (breadcrumbs, logs)
  - [ ] Add FAQ section for frequent issues
  - [ ] Document when to retry vs when to abort
  - [ ] Add performance implications of retry logic
  - [ ] Include contact/support information

- [ ] **Task 9: Integration with Existing Tools** (AC: 5)
  - [ ] Update all tool handlers to use enhanced error handling
  - [ ] Add appropriate recovery suggestions to each tool
  - [ ] Integrate error context tracking in tool operations
  - [ ] Add retry logic where appropriate (file operations, git operations)
  - [ ] Update tool tests to verify error handling improvements
  - [ ] Verify backward compatibility with Story 1.2 error handling
  - [ ] Unit test: Tools use enhanced error handling
  - [ ] Unit test: Recovery suggestions specific to each tool

- [ ] **Task 10: Comprehensive Testing** (AC: 9, 10)
  - [ ] Create `tests/unit/utils/error-context.test.ts` (8+ tests)
  - [ ] Create `tests/unit/utils/retry.test.ts` (10+ tests)
  - [ ] Create `tests/unit/utils/circuit-breaker.test.ts` (8+ tests)
  - [ ] Create `tests/unit/utils/fs-resilient.test.ts` (6+ tests)
  - [ ] Create `tests/unit/utils/git-resilient.test.ts` (6+ tests)
  - [ ] Update `tests/unit/utils/errors.test.ts` with enhanced error tests (8+ new tests)
  - [ ] Create `tests/integration/error-recovery.test.ts` (10+ tests)
  - [ ] Integration test: File operation retry on lock contention
  - [ ] Integration test: Git operation retry on lock files
  - [ ] Integration test: Circuit breaker prevents cascading failures
  - [ ] Integration test: Breadcrumbs track operation chains
  - [ ] Integration test: Recovery suggestions guide users
  - [ ] Verify coverage: 80%+ for all error handling files
  - [ ] Target: 30+ new tests total

## Dev Notes

### Previous Story Insights

**From Story 1.1** (COMPLETED):
- MCP server with logging infrastructure
- Type definitions established
- Testing framework configured

**From Story 1.2** (COMPLETED):
- Basic error hierarchy implemented (ContextualizerError, ValidationError, FileOperationError, ConflictError)
- wrapToolHandler pattern established
- 188 tests passing with 96.87% coverage

**From Story 1.3** (COMPLETED):
- Resource system patterns
- 218 tests passing with 97.85% coverage

**From Story 1.4** (COMPLETED - assumed):
- Prompt system patterns
- Integration test patterns refined

**Key Learnings**:
- Error handling is critical for user experience
- Placeholder implementations defer complex logic to later epics
- Comprehensive testing ensures reliability
- Documentation is essential for maintainability

### Architecture Overview

**Source Context**: This story implements error handling enhancements described in:
- [Source: architecture/mcp-server.md#error-handling-strategy]
- [Source: architecture/security-performance-testing.md#error-handling]
- [Source: prd.md#nfr6-nfr8] (Atomic operations, graceful degradation)

### Error Handling Enhancement Requirements

[Source: architecture/mcp-server.md#error-handling-strategy]

**Enhanced Error Class Hierarchy**:

```typescript
// Base class with enhancements
export class ContextualizerError extends Error {
  constructor(
    message: string,
    public code: string,
    public category: ErrorCategory,
    public details?: unknown,
    public recoverable: boolean = true,
    public recoverySuggestions: string[] = [],
    public isRetryable: boolean = false,
    public retryCount: number = 0
  ) {
    super(message);
    this.name = 'ContextualizerError';
    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, ContextualizerError);
    }
  }

  addRecoverySuggestion(suggestion: string): void {
    this.recoverySuggestions.push(suggestion);
  }

  incrementRetryCount(): void {
    this.retryCount++;
  }
}

type ErrorCategory =
  | 'validation'
  | 'filesystem'
  | 'git'
  | 'configuration'
  | 'network'
  | 'unknown';

// Enhanced subclasses
export class ValidationError extends ContextualizerError {
  constructor(message: string, details?: unknown) {
    super(message, 'VALIDATION_ERROR', 'validation', details, true, [], false);
    this.name = 'ValidationError';
    this.addRecoverySuggestion('Check parameter format and values');
    this.addRecoverySuggestion('Refer to tool documentation for valid inputs');
  }
}

export class FileOperationError extends ContextualizerError {
  constructor(message: string, details?: unknown, isRetryable: boolean = true) {
    super(message, 'FILE_OPERATION_ERROR', 'filesystem', details, true, [], isRetryable);
    this.name = 'FileOperationError';
    if (isRetryable) {
      this.addRecoverySuggestion('Operation will be retried automatically');
      this.addRecoverySuggestion('Check file permissions if error persists');
    } else {
      this.addRecoverySuggestion('Check file permissions and paths');
      this.addRecoverySuggestion('Verify disk space is available');
    }
  }
}

export class GitOperationError extends ContextualizerError {
  constructor(message: string, details?: unknown, isRetryable: boolean = true) {
    super(message, 'GIT_OPERATION_ERROR', 'git', details, true, [], isRetryable);
    this.name = 'GitOperationError';
    if (isRetryable) {
      this.addRecoverySuggestion('Operation will be retried automatically');
      this.addRecoverySuggestion('Check if git repository is locked by another process');
    } else {
      this.addRecoverySuggestion('Verify git repository is initialized');
      this.addRecoverySuggestion('Check git remote configuration');
    }
  }
}

export class NetworkError extends ContextualizerError {
  constructor(message: string, details?: unknown) {
    super(message, 'NETWORK_ERROR', 'network', details, true, [], true);
    this.name = 'NetworkError';
    this.addRecoverySuggestion('Operation will be retried automatically');
    this.addRecoverySuggestion('Check network connectivity');
    this.addRecoverySuggestion('Verify firewall settings if error persists');
  }
}

export class ConfigurationError extends ContextualizerError {
  constructor(message: string, details?: unknown) {
    super(message, 'CONFIGURATION_ERROR', 'configuration', details, true, [], false);
    this.name = 'ConfigurationError';
    this.addRecoverySuggestion('Check .contextualizer/config.yaml syntax');
    this.addRecoverySuggestion('Run diagnostics with run_doctor tool');
    this.addRecoverySuggestion('Refer to configuration documentation');
  }
}
```

### Error Context Tracking (Breadcrumbs)

[Source: architecture/mcp-server.md#error-handling-strategy]

**Breadcrumb System**:

```typescript
// src/utils/error-context.ts
import { AsyncLocalStorage } from 'async_hooks';

interface Breadcrumb {
  timestamp: Date;
  operation: string;
  details?: unknown;
}

class ErrorContext {
  private breadcrumbs: Breadcrumb[] = [];

  addBreadcrumb(operation: string, details?: unknown): void {
    this.breadcrumbs.push({
      timestamp: new Date(),
      operation,
      details,
    });
  }

  getBreadcrumbs(): Breadcrumb[] {
    return [...this.breadcrumbs];
  }

  clear(): void {
    this.breadcrumbs = [];
  }
}

// AsyncLocalStorage for context isolation
const errorContextStorage = new AsyncLocalStorage<ErrorContext>();

export function getErrorContext(): ErrorContext {
  let context = errorContextStorage.getStore();
  if (!context) {
    context = new ErrorContext();
  }
  return context;
}

export async function withErrorContext<T>(
  operation: string,
  fn: () => Promise<T>
): Promise<T> {
  const context = new ErrorContext();
  context.addBreadcrumb(operation);

  return errorContextStorage.run(context, async () => {
    try {
      return await fn();
    } catch (error) {
      // Attach breadcrumbs to error
      if (error instanceof ContextualizerError) {
        const breadcrumbs = context.getBreadcrumbs();
        error.details = {
          ...error.details,
          breadcrumbs,
        };
      }
      throw error;
    }
  });
}
```

### Retry Logic with Exponential Backoff

[Source: architecture/security-performance-testing.md#resilience-patterns]

**Retry Configuration**:

```typescript
// src/utils/retry.ts
export interface RetryConfig {
  maxAttempts: number;
  delayMs: number;
  backoffMultiplier: number;
  maxDelayMs: number;
}

export const DEFAULT_RETRY_CONFIG: RetryConfig = {
  maxAttempts: 3,
  delayMs: 100,
  backoffMultiplier: 2,
  maxDelayMs: 5000,
};

export async function retryWithBackoff<T>(
  fn: () => Promise<T>,
  config: Partial<RetryConfig> = {},
  isRetryableError: (error: unknown) => boolean = () => true
): Promise<T> {
  const finalConfig = { ...DEFAULT_RETRY_CONFIG, ...config };
  let lastError: unknown;
  let delay = finalConfig.delayMs;

  for (let attempt = 1; attempt <= finalConfig.maxAttempts; attempt++) {
    try {
      return await fn();
    } catch (error) {
      lastError = error;

      // Increment retry count if ContextualizerError
      if (error instanceof ContextualizerError) {
        error.incrementRetryCount();
      }

      // Check if error is retryable
      const shouldRetry =
        attempt < finalConfig.maxAttempts &&
        isRetryableError(error) &&
        (error instanceof ContextualizerError ? error.isRetryable : false);

      if (!shouldRetry) {
        throw error;
      }

      // Add breadcrumb for retry
      const context = getErrorContext();
      context.addBreadcrumb(`Retry attempt ${attempt}`, { error: String(error) });

      // Wait with exponential backoff
      await new Promise(resolve => setTimeout(resolve, delay));
      delay = Math.min(delay * finalConfig.backoffMultiplier, finalConfig.maxDelayMs);
    }
  }

  throw lastError;
}
```

### Circuit Breaker Pattern

[Source: architecture/security-performance-testing.md#resilience-patterns]

**Circuit Breaker Implementation**:

```typescript
// src/utils/circuit-breaker.ts
export enum CircuitState {
  CLOSED = 'CLOSED',     // Normal operation
  OPEN = 'OPEN',         // Failing, reject requests
  HALF_OPEN = 'HALF_OPEN' // Testing recovery
}

export interface CircuitBreakerConfig {
  failureThreshold: number;
  resetTimeoutMs: number;
  halfOpenMaxAttempts: number;
}

export const DEFAULT_CIRCUIT_CONFIG: CircuitBreakerConfig = {
  failureThreshold: 5,
  resetTimeoutMs: 60000, // 1 minute
  halfOpenMaxAttempts: 3,
};

export class CircuitBreaker {
  private state: CircuitState = CircuitState.CLOSED;
  private failureCount = 0;
  private successCount = 0;
  private lastFailureTime?: Date;

  constructor(
    private name: string,
    private config: CircuitBreakerConfig = DEFAULT_CIRCUIT_CONFIG
  ) {}

  async execute<T>(fn: () => Promise<T>): Promise<T> {
    // Check if circuit is open
    if (this.state === CircuitState.OPEN) {
      const now = new Date();
      const timeSinceFailure = now.getTime() - (this.lastFailureTime?.getTime() || 0);

      if (timeSinceFailure >= this.config.resetTimeoutMs) {
        // Try half-open state
        this.state = CircuitState.HALF_OPEN;
        this.successCount = 0;
      } else {
        throw new ContextualizerError(
          `Circuit breaker '${this.name}' is OPEN - too many failures`,
          'CIRCUIT_BREAKER_OPEN',
          'network',
          { state: this.state, failureCount: this.failureCount },
          false,
          ['Wait for circuit breaker to reset', 'Check underlying service health'],
          false
        );
      }
    }

    try {
      const result = await fn();
      this.onSuccess();
      return result;
    } catch (error) {
      this.onFailure();
      throw error;
    }
  }

  private onSuccess(): void {
    if (this.state === CircuitState.HALF_OPEN) {
      this.successCount++;
      if (this.successCount >= this.config.halfOpenMaxAttempts) {
        // Circuit recovered
        this.state = CircuitState.CLOSED;
        this.failureCount = 0;
        this.successCount = 0;
      }
    } else if (this.state === CircuitState.CLOSED) {
      // Reset failure count on success
      this.failureCount = 0;
    }
  }

  private onFailure(): void {
    this.failureCount++;
    this.lastFailureTime = new Date();

    if (this.state === CircuitState.HALF_OPEN) {
      // Half-open failure -> back to open
      this.state = CircuitState.OPEN;
    } else if (this.state === CircuitState.CLOSED) {
      if (this.failureCount >= this.config.failureThreshold) {
        // Too many failures -> open circuit
        this.state = CircuitState.OPEN;
      }
    }
  }

  getState(): CircuitState {
    return this.state;
  }

  reset(): void {
    this.state = CircuitState.CLOSED;
    this.failureCount = 0;
    this.successCount = 0;
    this.lastFailureTime = undefined;
  }
}

// Global circuit breakers
const circuitBreakers = new Map<string, CircuitBreaker>();

export function getCircuitBreaker(
  name: string,
  config?: CircuitBreakerConfig
): CircuitBreaker {
  if (!circuitBreakers.has(name)) {
    circuitBreakers.set(name, new CircuitBreaker(name, config));
  }
  return circuitBreakers.get(name)!;
}
```

### Enhanced Error Response Format

[Source: architecture/mcp-server.md#error-handling-strategy]

**Structured Error Response**:

```typescript
// src/utils/errors.ts - Enhanced wrapToolHandler
export function wrapToolHandler<T>(
  handler: (params: T) => Promise<ToolResult>
): (params: unknown) => Promise<ToolResult> {
  return async (params: unknown) => {
    try {
      const validatedParams = params as T;
      return await handler(validatedParams);
    } catch (error) {
      // Handle known Contextualizer errors
      if (error instanceof ContextualizerError) {
        const errorResponse = formatErrorResponse(error);
        logger.error({
          code: error.code,
          category: error.category,
          retryCount: error.retryCount
        }, 'Tool error');

        return {
          content: [{
            type: 'text',
            text: errorResponse,
          }],
          isError: true,
        };
      }

      // Handle unexpected errors
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger.error({ error }, 'Unexpected error in tool handler');

      return {
        content: [{
          type: 'text',
          text: `‚ùå Unexpected error: ${errorMessage}`,
        }],
        isError: true,
      };
    }
  };
}

function formatErrorResponse(error: ContextualizerError): string {
  let response = `‚ùå ${error.message}\n\n`;

  // Add error metadata
  response += `**Error Code**: ${error.code}\n`;
  response += `**Category**: ${error.category}\n`;

  // Add retry information
  if (error.isRetryable && error.retryCount > 0) {
    response += `**Retry Attempts**: ${error.retryCount}\n`;
  }

  response += '\n';

  // Add recovery suggestions
  if (error.recoverySuggestions.length > 0) {
    response += '**Recovery Suggestions**:\n';
    error.recoverySuggestions.forEach((suggestion, index) => {
      response += `${index + 1}. ${suggestion}\n`;
    });
    response += '\n';
  }

  // Add error details
  if (error.details) {
    response += '**Details**:\n';

    // Extract breadcrumbs if present
    const details = error.details as any;
    if (details.breadcrumbs && Array.isArray(details.breadcrumbs)) {
      response += '\nOperation trace:\n';
      details.breadcrumbs.forEach((breadcrumb: any, index: number) => {
        response += `  ${index + 1}. ${breadcrumb.operation}`;
        if (breadcrumb.details) {
          response += ` - ${JSON.stringify(breadcrumb.details)}`;
        }
        response += '\n';
      });

      // Show other details without breadcrumbs
      const { breadcrumbs, ...otherDetails } = details;
      if (Object.keys(otherDetails).length > 0) {
        response += '\n' + JSON.stringify(otherDetails, null, 2);
      }
    } else {
      response += JSON.stringify(error.details, null, 2);
    }
  }

  return response;
}
```

### Resilient File Operations

[Source: architecture/integration-data.md#file-system-operations]

**Filesystem Wrapper**:

```typescript
// src/utils/fs-resilient.ts
import * as fs from 'fs-extra';
import { FileOperationError } from './errors.js';
import { retryWithBackoff } from './retry.js';
import { getCircuitBreaker } from './circuit-breaker.js';
import { getErrorContext } from './error-context.js';

const fsCircuitBreaker = getCircuitBreaker('filesystem');

function isRetryableFileError(error: unknown): boolean {
  if (!(error instanceof Error)) return false;

  const retryableCodes = ['EBUSY', 'EACCES', 'EMFILE', 'EAGAIN'];
  return retryableCodes.some(code => (error as any).code === code);
}

export async function readFileWithRetry(
  path: string,
  encoding: BufferEncoding = 'utf8'
): Promise<string> {
  const context = getErrorContext();
  context.addBreadcrumb('readFileWithRetry', { path });

  return fsCircuitBreaker.execute(() =>
    retryWithBackoff(
      async () => {
        try {
          return await fs.readFile(path, encoding);
        } catch (error) {
          throw new FileOperationError(
            `Failed to read file: ${path}`,
            { path, error: String(error) },
            isRetryableFileError(error)
          );
        }
      },
      { maxAttempts: 3, delayMs: 100 },
      isRetryableFileError
    )
  );
}

export async function writeFileWithRetry(
  path: string,
  content: string,
  encoding: BufferEncoding = 'utf8'
): Promise<void> {
  const context = getErrorContext();
  context.addBreadcrumb('writeFileWithRetry', { path });

  return fsCircuitBreaker.execute(() =>
    retryWithBackoff(
      async () => {
        try {
          await fs.writeFile(path, content, encoding);
        } catch (error) {
          throw new FileOperationError(
            `Failed to write file: ${path}`,
            { path, error: String(error) },
            isRetryableFileError(error)
          );
        }
      },
      { maxAttempts: 3, delayMs: 100 },
      isRetryableFileError
    )
  );
}

export async function ensureDirWithRetry(path: string): Promise<void> {
  const context = getErrorContext();
  context.addBreadcrumb('ensureDirWithRetry', { path });

  return fsCircuitBreaker.execute(() =>
    retryWithBackoff(
      async () => {
        try {
          await fs.ensureDir(path);
        } catch (error) {
          throw new FileOperationError(
            `Failed to create directory: ${path}`,
            { path, error: String(error) },
            isRetryableFileError(error)
          );
        }
      },
      { maxAttempts: 3, delayMs: 100 },
      isRetryableFileError
    )
  );
}
```

### Resilient Git Operations

[Source: architecture/integration-data.md#git-operations]

**Git Wrapper**:

```typescript
// src/utils/git-resilient.ts
import simpleGit, { SimpleGit } from 'simple-git';
import { GitOperationError } from './errors.js';
import { retryWithBackoff } from './retry.js';
import { getCircuitBreaker } from './circuit-breaker.js';
import { getErrorContext } from './error-context.js';

const gitCircuitBreaker = getCircuitBreaker('git');

function isRetryableGitError(error: unknown): boolean {
  if (!(error instanceof Error)) return false;

  const message = error.message.toLowerCase();
  return (
    message.includes('lock') ||
    message.includes('timeout') ||
    message.includes('network') ||
    message.includes('connection')
  );
}

export async function gitWithRetry(
  operation: string,
  fn: (git: SimpleGit) => Promise<any>
): Promise<any> {
  const context = getErrorContext();
  context.addBreadcrumb('gitWithRetry', { operation });

  const git = simpleGit();

  return gitCircuitBreaker.execute(() =>
    retryWithBackoff(
      async () => {
        try {
          return await fn(git);
        } catch (error) {
          throw new GitOperationError(
            `Git operation '${operation}' failed`,
            { operation, error: String(error) },
            isRetryableGitError(error)
          );
        }
      },
      { maxAttempts: 3, delayMs: 200 },
      isRetryableGitError
    )
  );
}

// Example usage:
// await gitWithRetry('commit', (git) => git.commit('message'));
// await gitWithRetry('add', (git) => git.add('.'));
```

### File Locations

[Source: architecture/integration-data.md#file-system-layout]

**New Files to Create**:
- `src/utils/error-context.ts` - Error context and breadcrumb tracking
- `src/utils/retry.ts` - Retry logic with exponential backoff
- `src/utils/circuit-breaker.ts` - Circuit breaker implementation
- `src/utils/fs-resilient.ts` - Resilient filesystem operations
- `src/utils/git-resilient.ts` - Resilient git operations
- `docs/error-catalog.md` - Comprehensive error documentation
- `docs/troubleshooting.md` - User-facing troubleshooting guide

**Files to Modify**:
- `src/utils/errors.ts` - Enhance error classes and wrapToolHandler
- All tool handlers (`src/tools/*.ts`) - Integrate enhanced error handling

**Test Files to Create**:
- `tests/unit/utils/error-context.test.ts` - Error context tests
- `tests/unit/utils/retry.test.ts` - Retry logic tests
- `tests/unit/utils/circuit-breaker.test.ts` - Circuit breaker tests
- `tests/unit/utils/fs-resilient.test.ts` - Filesystem resilience tests
- `tests/unit/utils/git-resilient.test.ts` - Git resilience tests
- `tests/integration/error-recovery.test.ts` - Error recovery integration tests

**Test Files to Update**:
- `tests/unit/utils/errors.test.ts` - Add enhanced error class tests

### Testing

#### Testing Standards

[Source: architecture/security-performance-testing.md#testing-architecture]

**Test Framework**: Vitest (established in Story 1.1)

**Coverage Requirements**:
- Lines: 80%+
- Functions: 80%+
- Branches: 75%+
- Statements: 80%+

**Test File Structure**:
```
tests/
‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ errors.test.ts (existing, update with ~8 new tests)
‚îÇ       ‚îú‚îÄ‚îÄ error-context.test.ts (8+ tests)
‚îÇ       ‚îú‚îÄ‚îÄ retry.test.ts (10+ tests)
‚îÇ       ‚îú‚îÄ‚îÄ circuit-breaker.test.ts (8+ tests)
‚îÇ       ‚îú‚îÄ‚îÄ fs-resilient.test.ts (6+ tests)
‚îÇ       ‚îî‚îÄ‚îÄ git-resilient.test.ts (6+ tests)
‚îî‚îÄ‚îÄ integration/
    ‚îî‚îÄ‚îÄ error-recovery.test.ts (10+ tests)
```

#### Unit Test Requirements

**Error Context Tests** (8+ tests):
1. Breadcrumb addition
2. Breadcrumb retrieval
3. Context clearing
4. Nested operation tracking
5. AsyncLocalStorage isolation
6. withErrorContext wrapper
7. Breadcrumbs in error details
8. Multiple contexts don't interfere

**Retry Logic Tests** (10+ tests):
1. Successful operation (no retry)
2. Single retry succeeds
3. Multiple retries with exponential backoff
4. Max attempts respected
5. Non-retryable error fails immediately
6. Retryable error determined correctly
7. Delay calculation (exponential backoff)
8. Max delay cap respected
9. Retry count incremented
10. Breadcrumbs added on retry

**Circuit Breaker Tests** (8+ tests):
1. CLOSED state normal operation
2. Failures increment count
3. Threshold opens circuit
4. OPEN state rejects requests
5. Reset timeout transitions to HALF_OPEN
6. HALF_OPEN successes close circuit
7. HALF_OPEN failure reopens circuit
8. Reset method works

**Filesystem Resilience Tests** (6+ tests):
1. Read succeeds without retry
2. Read retries on EBUSY
3. Write retries on lock contention
4. Non-retryable filesystem errors
5. Circuit breaker integration
6. Breadcrumbs tracked

**Git Resilience Tests** (6+ tests):
1. Git operation succeeds without retry
2. Retries on lock file contention
3. Retries on network errors
4. Non-retryable git errors
5. Circuit breaker integration
6. Recovery suggestions included

**Enhanced Error Class Tests** (8+ new tests in errors.test.ts):
1. Recovery suggestions added
2. Error categories assigned
3. isRetryable flag set correctly
4. retryCount increments
5. formatErrorResponse structure
6. Breadcrumbs in formatted response
7. GitOperationError construction
8. NetworkError construction

#### Integration Test Requirements

[Source: architecture/security-performance-testing.md#integration-test-strategy]

**Error Recovery Integration Tests** (10+ tests):

1. **File Lock Contention Recovery**:
   - Simulate file lock
   - Verify retry attempts
   - Verify eventual success

2. **Git Lock Recovery**:
   - Simulate git lock file
   - Verify retry attempts
   - Verify lock released and operation succeeds

3. **Circuit Breaker Protection**:
   - Trigger circuit breaker open
   - Verify requests rejected
   - Verify circuit resets after timeout
   - Verify half-open recovery

4. **Breadcrumb Tracking**:
   - Multi-operation chain
   - Error occurs mid-chain
   - Verify complete breadcrumb trail in error

5. **Recovery Suggestions**:
   - Trigger various error types
   - Verify appropriate suggestions returned
   - Verify suggestions formatted correctly

6. **Retry Count Tracking**:
   - Operation fails multiple times
   - Verify retry count incremented
   - Verify retry count in error response

7. **Error Category Routing**:
   - Filesystem errors categorized correctly
   - Git errors categorized correctly
   - Network errors categorized correctly

8. **Exponential Backoff**:
   - Measure retry delays
   - Verify exponential increase
   - Verify max delay cap

9. **Non-Retryable Fast Fail**:
   - Trigger non-retryable error
   - Verify no retry attempts
   - Verify immediate failure

10. **Tool Integration**:
    - Tool uses enhanced error handling
    - Tool-specific recovery suggestions
    - Breadcrumbs track tool operations

**Example Integration Test**:
```typescript
import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
import * as fs from 'fs-extra';
import { readFileWithRetry } from '../../src/utils/fs-resilient';
import { getCircuitBreaker } from '../../src/utils/circuit-breaker';

describe('File Lock Recovery Integration', () => {
  let lockCount = 0;

  beforeEach(() => {
    lockCount = 0;
    getCircuitBreaker('filesystem').reset();
  });

  afterEach(() => {
    vi.restoreAllMocks();
  });

  it('retries on EBUSY and eventually succeeds', async () => {
    // Mock fs.readFile to fail twice with EBUSY, then succeed
    const mockReadFile = vi.spyOn(fs, 'readFile').mockImplementation(async () => {
      if (lockCount < 2) {
        lockCount++;
        const error: any = new Error('File is busy');
        error.code = 'EBUSY';
        throw error;
      }
      return 'file content';
    });

    const result = await readFileWithRetry('test.txt');

    expect(result).toBe('file content');
    expect(mockReadFile).toHaveBeenCalledTimes(3); // 2 failures + 1 success
  });

  it('includes breadcrumbs in error when max retries exceeded', async () => {
    const mockReadFile = vi.spyOn(fs, 'readFile').mockImplementation(async () => {
      const error: any = new Error('File is busy');
      error.code = 'EBUSY';
      throw error;
    });

    try {
      await readFileWithRetry('test.txt');
      expect.fail('Should have thrown');
    } catch (error: any) {
      expect(error.details.breadcrumbs).toBeDefined();
      expect(error.details.breadcrumbs.length).toBeGreaterThan(0);
      expect(error.retryCount).toBe(3);
    }
  });
});
```

### Performance Targets

[Source: architecture/security-performance-testing.md#performance-targets]

- **Error handling overhead**: < 5ms per operation
- **Retry delay**: 100ms base, exponential up to 5s max
- **Circuit breaker check**: < 1ms
- **Breadcrumb addition**: < 1ms
- **Error formatting**: < 10ms
- **File operation retry**: < 2s total (3 attempts √ó ~500ms)
- **Git operation retry**: < 3s total (3 attempts √ó ~800ms)

### Definition of Done

- [ ] All acceptance criteria met
- [ ] All tasks completed
- [ ] Enhanced error class hierarchy with recovery suggestions
- [ ] Error context tracking (breadcrumbs) implemented
- [ ] Retry logic with exponential backoff implemented
- [ ] Circuit breaker pattern implemented
- [ ] Resilient filesystem operations implemented
- [ ] Resilient git operations implemented
- [ ] Enhanced wrapToolHandler with structured responses
- [ ] Error catalog documentation complete
- [ ] Troubleshooting guide complete
- [ ] Unit tests: 30+ new tests total
- [ ] Integration tests: 10+ tests covering error recovery
- [ ] Test coverage: 80%+ lines, functions, statements
- [ ] Build completes without errors (`npm run build`)
- [ ] All tests pass (`npm test`)
- [ ] No TypeScript errors (`tsc --noEmit`)
- [ ] Code follows established patterns from previous stories
- [ ] Documentation added for all public APIs
- [ ] All existing tool handlers updated with enhanced error handling
- [ ] Backward compatibility maintained with Story 1.2 error handling

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-19 | 1.0.0 | Initial story draft created | Bob (Scrum Master) |

## Dev Agent Notes

### Implementation Priority

**Phase 1: Core Infrastructure** (Tasks 1-4):
1. Enhanced error classes
2. Error context tracking
3. Retry logic infrastructure
4. Enhanced wrapToolHandler

**Phase 2: Resilience Patterns** (Tasks 5-6):
1. Filesystem operation wrappers
2. Git operation wrappers

**Phase 3: Documentation & Integration** (Tasks 7-9):
1. Error catalog
2. Troubleshooting guide
3. Tool integration

**Phase 4: Testing** (Task 10):
1. Comprehensive unit tests
2. Integration tests
3. Coverage verification

### Key Design Decisions

**AsyncLocalStorage vs Manual Context**:
- Chose AsyncLocalStorage for automatic context isolation
- Prevents breadcrumb leakage between concurrent operations
- More robust than manual context passing

**Circuit Breaker Thresholds**:
- 5 failures to open circuit (balance between protection and sensitivity)
- 60s reset timeout (allows time for transient issues to resolve)
- 3 half-open attempts (verify stability before full recovery)

**Retry Configuration**:
- 3 max attempts (balance between resilience and performance)
- 100ms base delay (fast enough for user experience)
- 2x backoff multiplier (exponential growth)
- 5s max delay (prevent excessive waiting)

**Error Categories**:
- Aligned with system architecture layers
- Enables category-specific handling strategies
- Future-proof for additional categories

### Integration Considerations

**Backward Compatibility**:
- Existing error handling from Story 1.2 continues to work
- Enhanced features are additive (no breaking changes)
- Tools can adopt enhanced error handling incrementally

**Future Epic Integration**:
- Epic 2 (init_project): Use resilient file operations
- Epic 4 (hooks): Use git resilient operations
- Epic 5 (doctor): Use error recovery in checks
- Epic 6 (memory): Use resilient file operations for CLAUDE.md

**Performance Impact**:
- Retry logic adds latency only on failures
- Circuit breaker check is negligible (< 1ms)
- Breadcrumbs have minimal memory overhead
- Structured error formatting adds ~5ms

### Testing Strategy

**Mocking Transient Failures**:
- Use Vitest's `vi.spyOn()` to mock fs and git operations
- Simulate EBUSY, EACCES, lock file scenarios
- Count invocations to verify retry attempts

**Time-based Testing**:
- Use `vi.useFakeTimers()` for testing backoff delays
- Avoid real delays in test suite (speed)
- Test circuit breaker timeout transitions

**AsyncLocalStorage Testing**:
- Test concurrent operations don't share context
- Verify context isolation between tests
- Test nested operation tracking

**Integration Test Approach**:
- Real file system operations (not mocked)
- Real git repository (temporary)
- Verify end-to-end error recovery flows

### Documentation Standards

**Error Catalog Format**:
- Error code and name
- Category and severity
- When it occurs
- Recovery strategies
- Code examples
- Related troubleshooting entries

**Troubleshooting Guide Format**:
- Symptom description
- Root cause analysis
- Step-by-step resolution
- Prevention strategies
- When to seek help

---

**END OF STORY 1.5**
