# Story 1.4: Prompt System

<!-- Powered by BMAD‚Ñ¢ Core -->

## Status
üìù Draft - 2025-10-19

## Story

**As a** developer using Claude for AI-assisted development,
**I want** three MCP prompt templates for common workflows,
**so that** Claude can guide me through setup, health checks, and context optimization via pre-defined conversational flows.

## Acceptance Criteria

1. Prompt template architecture implemented with MCPPrompt interface
2. setup_wizard prompt template implemented with optional project_type argument
3. health_check prompt template implemented with no arguments
4. optimize_context prompt template implemented with optional strategy argument
5. All prompts registered in PROMPTS array and discoverable via prompts/list
6. Prompt retrieval via prompts/get works for all 3 prompts
7. Prompt providers return properly formatted PromptMessage arrays
8. Prompts return placeholder implementations (actual tool invocation comes in later epics)
9. Comprehensive unit tests for each prompt template
10. Integration tests verify prompt retrieval through MCP protocol

## Tasks / Subtasks

- [ ] **Task 1: Implement setup_wizard Prompt** (AC: 2, 7, 8)
  - [ ] Create `src/prompts/setup-wizard.ts`
  - [ ] Define prompt with name "setup_wizard"
  - [ ] Add optional argument: project_type (string, not required)
  - [ ] Implement provider function returning PromptMessage array
  - [ ] Return placeholder message about Epic 2 implementation
  - [ ] Include guidance on what tool will eventually be invoked (init_project)
  - [ ] Export setupWizardPrompt definition
  - [ ] Unit test: Prompt definition has correct metadata
  - [ ] Unit test: Provider returns valid PromptMessage array
  - [ ] Unit test: Message includes role "user" and text content
  - [ ] Unit test: Placeholder mentions Epic 2 and init_project tool
  - [ ] Unit test: Works with project_type argument provided
  - [ ] Unit test: Works without project_type argument (defaults)

- [ ] **Task 2: Implement health_check Prompt** (AC: 3, 7, 8)
  - [ ] Create `src/prompts/health-check.ts`
  - [ ] Define prompt with name "health_check"
  - [ ] No arguments required
  - [ ] Implement provider function returning PromptMessage array
  - [ ] Return placeholder message about Epic 5 implementation
  - [ ] Include guidance on what tool will eventually be invoked (run_doctor)
  - [ ] Export healthCheckPrompt definition
  - [ ] Unit test: Prompt definition has correct metadata
  - [ ] Unit test: Provider returns valid PromptMessage array
  - [ ] Unit test: Message includes role "user" and text content
  - [ ] Unit test: Placeholder mentions Epic 5 and run_doctor tool
  - [ ] Unit test: Works with no arguments

- [ ] **Task 3: Implement optimize_context Prompt** (AC: 4, 7, 8)
  - [ ] Create `src/prompts/optimize-context.ts`
  - [ ] Define prompt with name "optimize_context"
  - [ ] Add optional argument: strategy (string: "aggressive" | "balanced" | "conservative", not required)
  - [ ] Implement provider function returning PromptMessage array
  - [ ] Return placeholder message about future implementation
  - [ ] Include guidance on context management best practices
  - [ ] Export optimizeContextPrompt definition
  - [ ] Unit test: Prompt definition has correct metadata
  - [ ] Unit test: Provider returns valid PromptMessage array
  - [ ] Unit test: Message includes role "user" and text content
  - [ ] Unit test: Works with strategy argument provided
  - [ ] Unit test: Works without strategy argument (defaults to "balanced")
  - [ ] Unit test: All strategy values supported (aggressive, balanced, conservative)

- [ ] **Task 4: Register Prompts in Registry** (AC: 1, 5, 6)
  - [ ] Update `src/prompts/index.ts` to import all 3 prompts
  - [ ] Add all prompts to PROMPTS array export
  - [ ] Verify prompts are discoverable via ListPromptsRequestSchema handler (Story 1.1)
  - [ ] Verify prompt retrieval works via GetPromptRequestSchema handler (Story 1.1)
  - [ ] Unit test: PROMPTS array contains all 3 prompts
  - [ ] Unit test: Each prompt has required properties (name, description, provider)
  - [ ] Unit test: Prompt names are unique in registry
  - [ ] Unit test: Arguments arrays are properly formatted

- [ ] **Task 5: Integration Testing** (AC: 6, 10)
  - [ ] Create `tests/integration/prompt-retrieval.test.ts`
  - [ ] Test: prompts/list returns all 3 prompts with correct metadata
  - [ ] Test: prompts/get works for setup_wizard (with argument)
  - [ ] Test: prompts/get works for setup_wizard (without argument)
  - [ ] Test: prompts/get works for health_check
  - [ ] Test: prompts/get works for optimize_context (with strategy)
  - [ ] Test: prompts/get works for optimize_context (without strategy)
  - [ ] Test: prompts/get with invalid prompt name returns error
  - [ ] Test: Returned messages have correct format (role, content.type, content.text)
  - [ ] Test: Prompt descriptions are clear and informative

- [ ] **Task 6: Comprehensive Unit Testing** (AC: 9)
  - [ ] Create `tests/unit/prompts/setup-wizard.test.ts` with 8+ tests
  - [ ] Create `tests/unit/prompts/health-check.test.ts` with 6+ tests
  - [ ] Create `tests/unit/prompts/optimize-context.test.ts` with 8+ tests
  - [ ] Verify coverage: 80%+ for all prompt files
  - [ ] Verify all prompt providers are tested
  - [ ] Verify argument handling is tested

## Dev Notes

### Previous Story Insights

**From Story 1.1** (COMPLETED):
- MCP server skeleton with empty PROMPTS array ready
- Type definitions in place: MCPPrompt, PromptMessage
- Server handlers ready: ListPromptsRequestSchema, GetPromptRequestSchema
- Logger utility available for prompt logging
- Testing infrastructure (Vitest) configured

**From Story 1.2** (COMPLETED):
- Error handling infrastructure available (ContextualizerError hierarchy)
- Testing patterns established (unit + integration)
- Placeholder implementation pattern: return informative messages about future functionality
- 188 tests passing with 96.87% coverage baseline

**From Story 1.3** (COMPLETED):
- Resource system implemented (3 resources)
- Pattern established for read-only data providers
- Integration test patterns refined
- Total: 218 tests passing with 97.85% coverage

**Key Learnings**:
- Prompts are conversational workflow templates
- Prompts return PromptMessage arrays (not ToolResult like tools)
- Prompt providers receive arguments as Record<string, string>
- Placeholder prompts should guide users on what they will eventually do
- Integration tests verify full MCP protocol flow

### Architecture Overview

**Source Context**: This story implements prompts described in:
- [Source: architecture/mcp-server.md#prompt-system-interface]
- [Source: architecture/mcp-server.md#server-lifecycle]
- [Source: prd.md#epic-1-story-4]

### Prompt System Requirements

[Source: architecture/mcp-server.md#prompt-system-interface]

**MCPPrompt Interface**:
```typescript
interface MCPPrompt {
  name: string;
  description: string;
  arguments?: Array<{
    name: string;
    description: string;
    required?: boolean;
  }>;
  provider: (args: Record<string, string>) => Promise<PromptMessage[]>;
}

interface PromptMessage {
  role: "user" | "assistant";
  content: {
    type: "text" | "image" | "resource";
    text?: string;
  };
}
```

**Prompt Provider Pattern**:
Prompts are functions that return arrays of PromptMessage. They are:
- Asynchronous (return Promise<PromptMessage[]>)
- Conversational (return message arrays to guide user)
- Templated (can use arguments to customize messages)
- Fast (< 50ms target from Epic requirements)

### Prompt Specifications

#### 1. setup_wizard

[Source: architecture/mcp-server.md#prompt-system-interface]
[Source: prd.md#epic-1-story-4]

**Name**: `setup_wizard`
**Description**: Interactive project setup workflow with preset selection guidance
**Purpose**: Guide users through initial project setup by helping them choose the right preset

**Arguments**:
```typescript
[
  {
    name: "project_type",
    description: "Type of project (e.g., 'nextjs', 'react', 'node', 'typescript'). If not provided, provides general setup guidance.",
    required: false,
  }
]
```

**Placeholder Behavior** (Story 1.4):
Return conversational message guiding user on setup, mentioning that full implementation will invoke init_project tool in Epic 2.

**Expected Return**:
```typescript
[
  {
    role: "user",
    content: {
      type: "text",
      text: `I'd like to set up this project for AI-first development with Contextualizer.

${args.project_type ? `This is a ${args.project_type} project.` : 'Please detect the project type from package.json or file structure.'}

**Setup Process (Placeholder - Full implementation in Epic 2)**:

The setup_wizard prompt will guide you through:

1. **Project Detection**: Analyze package.json and project structure
2. **Preset Selection**: Recommend preset based on project type
   - minimal: Basic context monitoring, no pre-commit hooks
   - web-fullstack: Full setup with hooks, skills, agents (Next.js/React projects)
   - hackathon: Fast iteration mode, minimal overhead
3. **Configuration**: Customize thresholds and strictness levels
4. **Tool Invocation**: Execute init_project tool with selected preset

**What will be created**:
- .claude/hooks/user-prompt-submit (context monitoring)
- .claude/hooks/pre-commit (quality gates, optional)
- .claude/CLAUDE.md (project memory)
- .claude/skills/ (framework expertise, optional)
- .claude/agents/ (specialized subagents, optional)
- .contextualizer/config.yaml (configuration)

**For now**: You can manually invoke the init_project tool with your preferred preset.

Example: "Use the init_project tool with the web-fullstack preset"`
    }
  }
]
```

**Implementation Notes**:
- If project_type provided, include it in the message
- If not provided, ask Claude to detect it
- Explain the 3 available presets clearly
- Guide user on manual tool invocation for now
- Mention Epic 2 implementation

#### 2. health_check

[Source: architecture/mcp-server.md#prompt-system-interface]
[Source: prd.md#epic-1-story-4]

**Name**: `health_check`
**Description**: Comprehensive project health check and diagnostics workflow
**Purpose**: Guide users through diagnostic process to identify configuration issues

**Arguments**: None required

**Placeholder Behavior** (Story 1.4):
Return conversational message explaining diagnostics process, mentioning that full implementation will invoke run_doctor tool in Epic 5.

**Expected Return**:
```typescript
[
  {
    role: "user",
    content: {
      type: "text",
      text: `Please run a comprehensive health check on this project to identify any configuration issues or areas for improvement.

**Health Check Process (Placeholder - Full implementation in Epic 5)**:

The health_check prompt will guide you through:

1. **Configuration Validation**: Verify .contextualizer/config.yaml exists and is valid
2. **Hook Health**: Check that hooks are present, executable, and functioning
3. **Memory Structure**: Validate CLAUDE.md structure and completeness
4. **MCP Server Status**: Verify Contextualizer MCP server is accessible
5. **Best Practices Compliance**: Compare against Anthropic's Claude Code best practices
6. **Performance Checks**: Verify hooks execute within performance targets

**15+ Diagnostic Checks** (Epic 5):
- Setup checks (config exists, valid YAML, version compatibility)
- Hook checks (files exist, executable, syntax valid, performance)
- Memory checks (CLAUDE.md exists, structure valid, sections complete)
- MCP checks (server accessible, tools registered, resources available)
- Testing checks (test commands configured, passing)
- Workflow checks (git hooks working, commit flow smooth)

**Report Format**:
- Summary: X/15 checks passed
- Pass ‚úÖ: Check passed
- Warn ‚ö†Ô∏è: Non-critical issue, recommendation provided
- Fail ‚ùå: Critical issue, requires fix

**For now**: You can manually invoke the run_doctor tool to see placeholder output.

Example: "Use the run_doctor tool to check project health"`
    }
  }
]
```

**Implementation Notes**:
- No arguments needed
- Explain the comprehensive diagnostic process
- List the 15+ check categories
- Describe the report format (pass/warn/fail)
- Mention Epic 5 implementation
- Guide user on manual tool invocation

#### 3. optimize_context

[Source: prd.md#epic-1-story-4]

**Name**: `optimize_context`
**Description**: Context management optimization workflow with strategy selection
**Purpose**: Guide users through context optimization based on their preferred strategy

**Arguments**:
```typescript
[
  {
    name: "strategy",
    description: "Optimization strategy: 'aggressive' (clear often, minimize context), 'balanced' (recommended, clear at task boundaries), 'conservative' (preserve context, rare clearing). Defaults to 'balanced'.",
    required: false,
  }
]
```

**Placeholder Behavior** (Story 1.4):
Return conversational message about context management best practices, with strategy-specific guidance.

**Expected Return**:
```typescript
[
  {
    role: "user",
    content: {
      type: "text",
      text: `I'd like to optimize my context management with Contextualizer using a ${args.strategy || 'balanced'} strategy.

**Context Optimization Workflow (Placeholder - Full implementation in future epics)**:

**Your Strategy: ${args.strategy || 'balanced'}**

${args.strategy === 'aggressive' ? `**Aggressive Strategy**:
- Clear context frequently (every 5-10 interactions)
- Minimize CLAUDE.md content
- Use skills for framework knowledge instead of memory
- Set context thresholds: warning 70%, critical 85%
- Prioritize speed over context continuity` : ''}

${!args.strategy || args.strategy === 'balanced' ? `**Balanced Strategy** (Recommended):
- Clear context at natural task boundaries
- Comprehensive CLAUDE.md with essential patterns
- Mix of memory and skills for optimal performance
- Set context thresholds: warning 80%, critical 95%
- Balance continuity with performance` : ''}

${args.strategy === 'conservative' ? `**Conservative Strategy**:
- Preserve context across sessions
- Detailed CLAUDE.md with extensive documentation
- Rely on memory over skills
- Set context thresholds: warning 90%, critical 98%
- Prioritize continuity over performance` : ''}

**Context Management Best Practices**:

1. **Monitor Context Usage**: Watch for threshold warnings in hooks
2. **Task Boundaries**: Natural points to clear context:
   - Completing a feature
   - Switching domains (frontend ‚Üí backend)
   - Starting a new work session
   - After major debugging sessions

3. **Memory vs Context Trade-offs**:
   - Memory (CLAUDE.md): Persistent across all sessions
   - Context: Current conversation, temporary
   - Use memory for patterns, context for current task

4. **Optimization Tools** (Future Implementation):
   - configure_hooks: Adjust thresholds for your strategy
   - manage_memory: Optimize CLAUDE.md structure
   - Task boundary detection: Automatic suggestions

**For now**: Manually adjust your context thresholds in .contextualizer/config.yaml based on your preferred strategy.`
    }
  }
]
```

**Implementation Notes**:
- Default strategy to "balanced" if not provided
- Include strategy-specific guidance (conditional content)
- Explain the three strategy types clearly
- Provide actionable best practices
- Mention future tool integration
- Guide user on manual configuration for now

### Prompt Implementation Pattern

[Source: architecture/mcp-server.md#prompt-system-interface]

**Standard Prompt Structure**:
```typescript
// src/prompts/example-prompt.ts
import type { MCPPrompt, PromptMessage } from '../types/mcp.js';

/**
 * Provider function for example prompt
 */
async function examplePromptProvider(args: Record<string, string>): Promise<PromptMessage[]> {
  // Extract arguments with defaults
  const argValue = args.arg_name || 'default_value';

  // Generate conversational message
  const messageText = `Your conversational prompt text here using ${argValue}`;

  return [
    {
      role: "user",
      content: {
        type: "text",
        text: messageText,
      },
    },
  ];
}

/**
 * Example prompt definition
 */
export const examplePrompt: MCPPrompt = {
  name: "example_prompt",
  description: "Description of what this prompt guides the user through",
  arguments: [
    {
      name: "arg_name",
      description: "Description of argument purpose and valid values",
      required: false,
    },
  ],
  provider: examplePromptProvider,
};
```

**Key Patterns**:
- Provider functions are async (return Promise<PromptMessage[]>)
- Provider functions receive arguments as Record<string, string>
- Return array with single "user" role message (most common)
- Use template literals for multi-line conversational text
- Apply default values for optional arguments

### File Locations

[Source: architecture/integration-data.md#file-system-layout]

**New Files to Create**:
- `src/prompts/setup-wizard.ts` - setup_wizard prompt implementation
- `src/prompts/health-check.ts` - health_check prompt implementation
- `src/prompts/optimize-context.ts` - optimize_context prompt implementation

**Files to Modify**:
- `src/prompts/index.ts` - Import and register all 3 prompts in PROMPTS array

**Test Files to Create**:
- `tests/unit/prompts/setup-wizard.test.ts` - setup_wizard tests
- `tests/unit/prompts/health-check.test.ts` - health_check tests
- `tests/unit/prompts/optimize-context.test.ts` - optimize_context tests
- `tests/integration/prompt-retrieval.test.ts` - Prompt retrieval integration tests

### Server Integration

[Source: architecture/mcp-server.md#server-lifecycle]

**Prompt Handlers** (already implemented in Story 1.1):

```typescript
// prompts/list handler
server.setRequestHandler(ListPromptsRequestSchema, async () => ({
  prompts: PROMPTS.map(p => ({
    name: p.name,
    description: p.description,
    arguments: p.arguments
  })),
}));

// prompts/get handler
server.setRequestHandler(GetPromptRequestSchema, async (request) => {
  const prompt = PROMPTS.find(p => p.name === request.params.name);
  if (!prompt) throw new Error(`Unknown prompt: ${request.params.name}`);

  const messages = await prompt.provider(request.params.arguments || {});
  return { messages };
});
```

**No Changes Required** to server.ts - handlers are already in place from Story 1.1.

### Logging Integration

[Source: architecture/mcp-server.md#server-lifecycle]

**Prompt Logging Pattern**:
```typescript
import { logger } from '../utils/logger.js';

async function promptProvider(args: Record<string, string>): Promise<PromptMessage[]> {
  logger.debug({ prompt: 'prompt_name', args }, 'Prompt invoked');

  // Generate prompt messages
  const messages = [ /* ... */ ];

  return messages;
}
```

**Logger Available** (from Story 1.1):
- `logger.debug()` - Debug level (use for prompt invocations)
- `logger.info()` - Info level
- `logger.error()` - Error level

### Testing Strategy

#### Testing Standards

[Source: architecture/security-performance-testing.md#testing-architecture]

**Test Framework**: Vitest (already configured)

**Coverage Requirements**:
- Lines: 80%+
- Functions: 80%+
- Branches: 75%+
- Statements: 80%+

**Test File Structure**:
```
tests/
‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îî‚îÄ‚îÄ prompts/
‚îÇ       ‚îú‚îÄ‚îÄ setup-wizard.test.ts
‚îÇ       ‚îú‚îÄ‚îÄ health-check.test.ts
‚îÇ       ‚îî‚îÄ‚îÄ optimize-context.test.ts
‚îî‚îÄ‚îÄ integration/
    ‚îî‚îÄ‚îÄ prompt-retrieval.test.ts
```

#### Unit Test Requirements

**Each Prompt Test File Should Include**:
1. Prompt definition tests (correct name, description, arguments)
2. Provider returns valid PromptMessage array
3. Message structure tests (role, content.type, content.text)
4. Argument handling tests (with and without optional args)
5. Default value tests (for optional arguments)
6. Message content validation (includes expected guidance)
7. Placeholder indication tests (mentions correct Epic)
8. Edge cases (empty args, invalid args handled gracefully)

**setup_wizard Tests**:
1. Prompt definition has correct metadata
2. Provider returns valid PromptMessage array
3. Message has role "user" and type "text"
4. Works with project_type argument provided
5. Works without project_type argument (defaults)
6. Message includes all 3 presets (minimal, web-fullstack, hackathon)
7. Message mentions Epic 2 and init_project tool
8. Message provides manual invocation guidance

**health_check Tests**:
1. Prompt definition has correct metadata
2. Provider returns valid PromptMessage array
3. Message has role "user" and type "text"
4. Works with no arguments
5. Message lists 15+ diagnostic check categories
6. Message mentions Epic 5 and run_doctor tool
7. Message describes report format (pass/warn/fail)

**optimize_context Tests**:
1. Prompt definition has correct metadata
2. Provider returns valid PromptMessage array
3. Message has role "user" and type "text"
4. Works with strategy "aggressive"
5. Works with strategy "balanced"
6. Works with strategy "conservative"
7. Works without strategy argument (defaults to "balanced")
8. Message includes strategy-specific guidance

**Example Unit Test Pattern**:
```typescript
import { describe, it, expect } from 'vitest';
import { setupWizardPrompt } from '../../src/prompts/setup-wizard';

describe('setup_wizard prompt', () => {
  describe('prompt definition', () => {
    it('has correct metadata', () => {
      expect(setupWizardPrompt.name).toBe('setup_wizard');
      expect(setupWizardPrompt.description).toBeTruthy();
      expect(setupWizardPrompt.arguments).toHaveLength(1);
      expect(setupWizardPrompt.arguments[0].name).toBe('project_type');
      expect(setupWizardPrompt.arguments[0].required).toBe(false);
      expect(setupWizardPrompt.provider).toBeTypeOf('function');
    });
  });

  describe('provider behavior', () => {
    it('returns valid PromptMessage array', async () => {
      const messages = await setupWizardPrompt.provider({});
      expect(Array.isArray(messages)).toBe(true);
      expect(messages).toHaveLength(1);
    });

    it('message has correct structure', async () => {
      const messages = await setupWizardPrompt.provider({});
      expect(messages[0].role).toBe('user');
      expect(messages[0].content.type).toBe('text');
      expect(messages[0].content.text).toBeTruthy();
    });

    it('works with project_type argument', async () => {
      const messages = await setupWizardPrompt.provider({ project_type: 'nextjs' });
      expect(messages[0].content.text).toContain('nextjs');
    });

    it('works without project_type argument', async () => {
      const messages = await setupWizardPrompt.provider({});
      expect(messages[0].content.text).toContain('detect');
    });

    it('message includes all 3 presets', async () => {
      const messages = await setupWizardPrompt.provider({});
      const text = messages[0].content.text!;
      expect(text).toContain('minimal');
      expect(text).toContain('web-fullstack');
      expect(text).toContain('hackathon');
    });

    it('mentions Epic 2 and init_project tool', async () => {
      const messages = await setupWizardPrompt.provider({});
      const text = messages[0].content.text!;
      expect(text).toContain('Epic 2');
      expect(text).toContain('init_project');
    });
  });
});
```

#### Integration Test Requirements

[Source: architecture/security-performance-testing.md#integration-test-strategy]

**Test Scenarios**:
1. prompts/list returns all 3 prompts
2. prompts/list includes correct metadata (name, description, arguments)
3. prompts/get succeeds for setup_wizard (with project_type)
4. prompts/get succeeds for setup_wizard (without project_type)
5. prompts/get succeeds for health_check
6. prompts/get succeeds for optimize_context (with strategy)
7. prompts/get succeeds for optimize_context (without strategy)
8. prompts/get with invalid prompt name returns error
9. Returned messages have correct format
10. Message text is properly formatted and readable

**Example Integration Test**:
```typescript
import { describe, it, expect, beforeAll, afterAll } from 'vitest';
import { spawn } from 'child_process';
import type { ChildProcess } from 'child_process';

describe('Prompt Retrieval Integration', () => {
  let server: ChildProcess;

  beforeAll(async () => {
    server = spawn('node', ['dist/server.js']);
    await new Promise(resolve => setTimeout(resolve, 1000));
  });

  afterAll(() => {
    server.kill();
  });

  it('lists all 3 prompts', async () => {
    server.stdin.write(JSON.stringify({
      jsonrpc: '2.0',
      method: 'prompts/list',
      id: 1,
    }) + '\n');

    const response = await new Promise<any>((resolve) => {
      server.stdout.once('data', (data) => {
        resolve(JSON.parse(data.toString()));
      });
    });

    expect(response.result.prompts).toHaveLength(3);
    expect(response.result.prompts.map(p => p.name)).toContain('setup_wizard');
    expect(response.result.prompts.map(p => p.name)).toContain('health_check');
    expect(response.result.prompts.map(p => p.name)).toContain('optimize_context');
  });

  it('retrieves setup_wizard with argument', async () => {
    server.stdin.write(JSON.stringify({
      jsonrpc: '2.0',
      method: 'prompts/get',
      params: {
        name: 'setup_wizard',
        arguments: { project_type: 'nextjs' },
      },
      id: 2,
    }) + '\n');

    const response = await new Promise<any>((resolve) => {
      server.stdout.once('data', (data) => {
        resolve(JSON.parse(data.toString()));
      });
    });

    expect(response.result.messages).toHaveLength(1);
    expect(response.result.messages[0].role).toBe('user');
    expect(response.result.messages[0].content.type).toBe('text');
    expect(response.result.messages[0].content.text).toContain('nextjs');
  });

  it('retrieves health_check', async () => {
    server.stdin.write(JSON.stringify({
      jsonrpc: '2.0',
      method: 'prompts/get',
      params: { name: 'health_check' },
      id: 3,
    }) + '\n');

    const response = await new Promise<any>((resolve) => {
      server.stdout.once('data', (data) => {
        resolve(JSON.parse(data.toString()));
      });
    });

    expect(response.result.messages).toHaveLength(1);
    expect(response.result.messages[0].content.text).toContain('health check');
    expect(response.result.messages[0].content.text).toContain('Epic 5');
  });

  it('retrieves optimize_context with strategy', async () => {
    server.stdin.write(JSON.stringify({
      jsonrpc: '2.0',
      method: 'prompts/get',
      params: {
        name: 'optimize_context',
        arguments: { strategy: 'aggressive' },
      },
      id: 4,
    }) + '\n');

    const response = await new Promise<any>((resolve) => {
      server.stdout.once('data', (data) => {
        resolve(JSON.parse(data.toString()));
      });
    });

    expect(response.result.messages).toHaveLength(1);
    expect(response.result.messages[0].content.text).toContain('aggressive');
  });
});
```

### Performance Targets

[Source: prd.md#epic-1-story-4]
[Source: architecture/security-performance-testing.md#performance-targets]

- **Prompt retrieval**: < 50ms (from Epic 1 Story 4 requirements)
- **Provider execution**: < 10ms (static template rendering, no I/O)
- **Message formatting**: < 5ms (template literal rendering)

### Implementation Notes

**Placeholder Implementation Strategy**:
1. All prompts return conversational guidance messages
2. No actual tool invocation (tools invoked manually by user for now)
3. Messages should be helpful, educational, and actionable
4. Clearly indicate which Epic will implement full automation
5. Provide manual workaround instructions (invoke tools directly)

**Message Content Guidelines**:
- Use clear, conversational language
- Break content into logical sections with headers
- Use bullet points and numbered lists for readability
- Include concrete examples where helpful
- Explain the "why" (purpose) and "what" (implementation)
- Guide users on current manual alternatives

**Argument Handling**:
- All arguments are strings (Record<string, string>)
- Apply sensible defaults for optional arguments
- Use conditional content based on argument values
- Handle missing arguments gracefully (don't crash)

**TypeScript Best Practices**:
- Use template literals for multi-line messages
- Define provider functions separately for testability
- Export prompt definitions as const
- No `any` types except for MCP SDK compatibility
- Use type imports for MCPPrompt and PromptMessage

**Testing Focus**:
- Verify message structure (role, content.type, content.text)
- Verify argument handling (with/without optional args)
- Verify message content includes expected guidance
- Verify placeholder messages mention correct Epics
- Integration tests verify full MCP protocol flow

**Dependencies** (already installed):
- `@modelcontextprotocol/sdk` - MCP types
- `pino` - Logger

### Definition of Done

- [ ] All acceptance criteria met
- [ ] All tasks completed
- [ ] 3 prompts implemented (setup_wizard, health_check, optimize_context)
- [ ] All prompts registered in PROMPTS array
- [ ] Unit tests: 30+ tests total (8+ setup_wizard, 6+ health_check, 8+ optimize_context)
- [ ] Integration tests: 10+ tests covering all prompts
- [ ] Test coverage: 80%+ lines, functions, statements
- [ ] Build completes without errors (`npm run build`)
- [ ] All tests pass (`npm test`)
- [ ] No TypeScript errors (`tsc --noEmit`)
- [ ] Code follows established patterns from Story 1.1-1.3
- [ ] Documentation comments added to all public APIs

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-19 | 1.0.0 | Initial story draft created | Bob (Scrum Master) |

## Dev Agent Record

### Agent Model Used
- **Model**: (To be filled by Dev Agent)
- **Agent**: (To be filled by Dev Agent)
- **Date**: (To be filled by Dev Agent)

### Debug Log References
- (To be filled by Dev Agent)

### Completion Notes List
- (To be filled by Dev Agent)

### File List
- (To be filled by Dev Agent)

## QA Results

**QA Agent**: (To be filled by QA Agent)
**QA Date**: (To be filled by QA Agent)
**QA Status**: (To be filled by QA Agent)

### Acceptance Criteria Validation
- (To be filled by QA Agent)

### Test Results
- (To be filled by QA Agent)

### Issues Found
- (To be filled by QA Agent)

### QA Recommendation
- (To be filled by QA Agent)
